{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMakerのいい感じの使い方を考える\n",
    "\n",
    "- SageMakerの基礎はこちらをご覧ください\n",
    "    - [BlackBeltセミナー 基礎編](https://aws.amazon.com/jp/blogs/news/webinar-bb-amazon-sagemaker-basic-session-2019/) \n",
    "    - [BlackBeltセミナー 発展編](https://aws.amazon.com/jp/blogs/news/webinar-bb-amazon-sagemaker-advanced-session-2019/)\n",
    "    - [SageMakerハンズオン](https://pages.awscloud.com/event_JAPAN_hands-on-ml_ondemand.html) \n",
    "- 今回はSageMakerのノートブックインスタンスを利用せず、モデルの開発やデバッグは手元のPC上のJupyter Notebookを利用します\n",
    "    - もちろんJupyter notebookの環境構築の手間は掛かりますが、モデルの開発や小規模なデータでの検証には費用が掛からず使い慣れたPCを利用したいというケースを想定しています\n",
    "- 学習と推論はSageMaker上で行います\n",
    "- コードはgitで管理します\n",
    "- 運用についても最後に加筆しました"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local環境の設定\n",
    "手元のPCに必要なpython packageをinstallします。Jupyter NotebookのインストールやpyenvなどでのPythonの環境構築に関しては省略します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (1.44.3)\n",
      "Requirement already satisfied: tensorflow in /Users/kiiwami/.local/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: keras in /Users/kiiwami/.local/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/kiiwami/.local/lib/python3.6/site-packages (3.1.2)\n",
      "Requirement already satisfied: protobuf>=3.1 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from sagemaker) (3.6.1)\n",
      "Requirement already satisfied: requests<2.21,>=2.20.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from sagemaker) (2.20.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from sagemaker) (1.3.1)\n",
      "Requirement already satisfied: boto3>=1.9.213 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from sagemaker) (1.9.218)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from sagemaker) (1.17.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.0.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: h5py in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kiiwami/.local/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kiiwami/.local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/kiiwami/.local/lib/python3.6/site-packages (from matplotlib) (2.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /Users/kiiwami/.local/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (42.0.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker) (1.24.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker) (2018.10.15)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from boto3>=1.9.213->sagemaker) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from boto3>=1.9.213->sagemaker) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.218 in /Users/kiiwami/.local/lib/python3.6/site-packages (from boto3>=1.9.213->sagemaker) (1.12.253)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/kiiwami/.local/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.7.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.218->boto3>=1.9.213->sagemaker) (0.15.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/kiiwami/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /Users/kiiwami/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/kiiwami/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/kiiwami/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/var/pyenv/versions/3.6.0/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.5)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install sagemaker tensorflow keras matplotlib --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local環境にデータセットをダウンロード\n",
    "Local環境ではデータセットの一部を対象に数epochの学習を行い、モデルやコードの検証を行います。ここでは手書き数字画像認識のデータセットであるMNISTを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 小規模な検証用にデータセットをダウンロード\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok = True)\n",
    "\n",
    "np.savez('./data/train', image=x_train, label=y_train)\n",
    "np.savez('./data/test', image=x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成\n",
    "\n",
    "SageMakerで、Tensorflow、Chainer、Pytorchなどのフレームワークを利用して深層学習を行うためには、このnotebook以外に**学習スクリプトを作成する必要があります**。学習スクリプトとはモデルや学習方法を記述した.pyファイルで、今回は`keras_tf_mnist.py`という学習スクリプトを同じフォルダに用意しています。SageMaker python SDKのfit()メソッドを呼び出すと、entry_pointに指定したスクリプトを起点に学習が行われます。\n",
    "\n",
    "学習スクリプトの`__main__`関数内に、学習時に実行されるコード(モデルの記述や学習方法)を記載すればよく、SageMaker外で利用しているコードを概ねそのまま利用することができます。また、環境変数経由で学習用データの場所や GPU の数などを取得することが可能です。これは `argparse` 経由で `main` 関数内で受け取ることができます。詳細は[こちら](https://sagemaker.readthedocs.io/en/stable/using_tf.html#train-a-model-with-tensorflow)をご覧ください。\n",
    "\n",
    "以下のセルを実行して学習スクリプトの中身を表示してみます。すると以下のような点が確認できます。\n",
    "\n",
    "**1. 以下のmain guardの中に、学習してモデルを保存するまでのコードを書くようにします。**\n",
    "\n",
    "```python\n",
    "    if __name__ == '__main__':\n",
    "```\n",
    "\n",
    "**2. Main guardの最初には、引数から学習時に指定したハイパーパラメータを取得するコードや、環境変数からSageMakerの指定する学習データやモデルの保存場所を受け取るコードを書きます。詳細は[こちら](https://sagemaker.readthedocs.io/en/stable/using_tf.html#prepare-a-script-mode-training-script)**\n",
    "\n",
    "```python\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # 引数から学習時に指定したハイパーパラメータを取得するコード\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch-size', type=int, default=100)\n",
    "    parser.add_argument('--n-class', type=int, default=10)\n",
    "\n",
    "    # 環境変数からSageMakerの指定する情報を取得するコード\n",
    "    \n",
    "    # SageMakerは学習時に学習用データをS3からあるローカルディレクトリにコピーします。\n",
    "    # os.environ['SM_CHANNEL_TRAINING']にはそのパスが格納されるため、そのパスから学習用データを読み込みます\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    # 学習後はos.environ['SM_MODEL_DIR']にモデルを保存して下さい。SageMakerは自動的にモデルをS3にコピーします\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "```\n",
    "**3. 学習完了後、KerasのモデルでなくTensorflow Servingでデプロイ可能なモデルとして保存します。**\n",
    "\n",
    "Tensorflow Serving で利用できるようにモデルを保存します。\n",
    "\n",
    "```python\n",
    "    sess = K.get_session()\n",
    "    tf.saved_model.simple_save(\n",
    "        sess,\n",
    "        os.path.join(args.model_dir, 'model/1'),\n",
    "        inputs={'inputs': model.input},\n",
    "        outputs={t.name: t for t in model.outputs})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras.models\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sequential\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras.layers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dense, Dropout, Activation, Flatten\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras.layers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Conv2D, MaxPooling2D\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m backend \u001b[34mas\u001b[39;49;00m K\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \n",
      "    \u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    Put a script for \"loading data downloaded from S3\" and\u001b[39;49;00m\n",
      "\u001b[33m    \"receiving arguments passed via API\"\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\n",
      "        \n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n-class\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# input data and model directories\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    args, _ = parser.parse_known_args()\n",
      "    \n",
      "    batch_size = args.batch_size\n",
      "    epochs = args.epochs\n",
      "    num_classes = args.n_class\n",
      "    train_dir = args.train\n",
      "    \n",
      "    x_train = np.load(os.path.join(train_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mimage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    y_train = np.load(os.path.join(train_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    x_test = np.load(os.path.join(train_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtest.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mimage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    y_test = np.load(os.path.join(train_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtest.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    \n",
      "    \u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    Keras script starts here.\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\n",
      "    \u001b[37m# input image dimensions\u001b[39;49;00m\n",
      "    img_rows, img_cols = \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m K.image_data_format() == \u001b[33m'\u001b[39;49;00m\u001b[33mchannels_first\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        x_train = x_train.reshape(x_train.shape[\u001b[34m0\u001b[39;49;00m], \u001b[34m1\u001b[39;49;00m, img_rows, img_cols)\n",
      "        x_test = x_test.reshape(x_test.shape[\u001b[34m0\u001b[39;49;00m], \u001b[34m1\u001b[39;49;00m, img_rows, img_cols)\n",
      "        input_shape = (\u001b[34m1\u001b[39;49;00m, img_rows, img_cols)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        x_train = x_train.reshape(x_train.shape[\u001b[34m0\u001b[39;49;00m], img_rows, img_cols, \u001b[34m1\u001b[39;49;00m)\n",
      "        x_test = x_test.reshape(x_test.shape[\u001b[34m0\u001b[39;49;00m], img_rows, img_cols, \u001b[34m1\u001b[39;49;00m)\n",
      "        input_shape = (img_rows, img_cols, \u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "    x_train = x_train.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    x_test = x_test.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    x_train /= \u001b[34m255\u001b[39;49;00m\n",
      "    x_test /= \u001b[34m255\u001b[39;49;00m\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mx_train shape:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, x_train.shape)\n",
      "    \u001b[34mprint\u001b[39;49;00m(x_train.shape[\u001b[34m0\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33mtrain samples\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mprint\u001b[39;49;00m(x_test.shape[\u001b[34m0\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33mtest samples\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# convert class vectors to binary class matrices\u001b[39;49;00m\n",
      "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
      "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
      "\n",
      "    model = Sequential()\n",
      "    model.add(Flatten(input_shape=input_shape))\n",
      "    model.add(Dense(\u001b[34m1000\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    model.add(Dense(\u001b[34m1000\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    model.add(Dense(num_classes, activation=\u001b[33m'\u001b[39;49;00m\u001b[33msoftmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \n",
      "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
      "                  optimizer=keras.optimizers.Adadelta(),\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    model.fit(x_train, y_train,\n",
      "              batch_size=batch_size,\n",
      "              epochs=epochs,\n",
      "              verbose=\u001b[34m1\u001b[39;49;00m,\n",
      "              validation_data=(x_test, y_test))\n",
      "    score = model.evaluate(x_test, y_test, verbose=\u001b[34m0\u001b[39;49;00m)\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTest loss:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, score[\u001b[34m0\u001b[39;49;00m])\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTest accuracy:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, score[\u001b[34m1\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    Save Keras model as a model for tensorflow serving\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\n",
      "    sess = K.get_session()\n",
      "    tf.saved_model.simple_save(\n",
      "        sess,\n",
      "        os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel/1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\n",
      "        inputs={\u001b[33m'\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.input},\n",
      "        outputs={t.name: t \u001b[34mfor\u001b[39;49;00m t \u001b[35min\u001b[39;49;00m model.outputs})\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'keras_tf_mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local環境での学習\n",
    "まずLocal環境でDockerを起動します。Macをご利用の場合、[こちら](https://docs.docker.com/docker-for-mac/install/)を参考にDocker.appをインストールして起動して下さい。\n",
    "\n",
    "SageMaker Python SDKで学習や推論を行なうためには、SageMaker Estimatorを利用します。今回はTensorflowをバックエンドとして学習するため、TensorFlowのEstimatorを作成し、`fit()` メソッドで学習ジョブを実行します。 `entry_point` で指定したスクリプトが、学習用のコンテナ内で実行されます。\n",
    "\n",
    "Local環境で学習を行うためには、`instance_type`に`local`(CPU利用)もしくは`local_gpu`(GPU利用)を設定します。ECRから学習用のコンテナイメージを取得し、Local環境上でコンテナが実行されます。この[ローカルモード](https://aws.amazon.com/jp/blogs/news/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/)は学習用インスタンスを起動する時間を省略できるため、アルゴリズムのテストやデバッグに適しています。初回の起動時のみ2GB程のコンテナイメージを取得するための時間が掛かる点にご注意下さい。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmphz0ajxx0_algo-1-nzgj2_1 ... \n",
      "\u001b[1BAttaching to tmphz0ajxx0_algo-1-nzgj2_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Using TensorFlow backend.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m /usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m x_train shape: (60000, 28, 28, 1)\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m 60000 train samples\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m 10000 test samples\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m WARNING: Logging before flag parsing goes to stderr.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:57.650169 140469253052160 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:57.667522 140469253052160 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:57.678768 140469253052160 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:57.721529 140469253052160 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:57.729411 140469253052160 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:57.891767 140469253052160 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:36:58.006560 140469253052160 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Train on 60000 samples, validate on 10000 samples\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Epoch 1/2\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m 2019-11-30 14:36:58.270547: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "60000/60000 [==============================] - 22s 361us/step - loss: 0.2250 - acc: 0.9314 - val_loss: 0.1462 - val_acc: 0.9548\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Epoch 2/2\n",
      "60000/60000 [==============================] - 20s 335us/step - loss: 0.0874 - acc: 0.9733 - val_loss: 0.1242 - val_acc: 0.9619\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Test loss: 0.12422378046638333\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Test accuracy: 0.9619\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:37:40.792847 140469253052160 deprecation.py:323] From keras_tf_mnist.py:97: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m W1130 14:37:40.794075 140469253052160 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-nzgj2_1  |\u001b[0m This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "\u001b[36mtmphz0ajxx0_algo-1-nzgj2_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "CPU times: user 1.5 s, sys: 271 ms, total: 1.77 s\n",
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "LOGGER = logging.getLogger('sagemaker')\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "local_estimator = TensorFlow(entry_point = \"keras_tf_mnist.py\",\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"local\",\n",
    "          framework_version=\"1.14.0\",\n",
    "          py_version='py3',\n",
    "          script_mode=True,\n",
    "          hyperparameters={'batch-size': 64,\n",
    "                         'n-class': 10,\n",
    "                         'epochs': 2})\n",
    "\n",
    "local_estimator.fit(\"file://data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local環境で推論用APIを起動\n",
    "\n",
    "推論を行うために学習したモデルをデプロイします。`deploy()` メソッドでは、デプロイ先エンドポイントのインスタンス数、インスタンスタイプを指定します。ここでは`instance_type`に`local`を指定します。それによりローカル環境で推論APIのコンテナを起動し動作を確認します。\n",
    "\n",
    "SageMakerでTensorFlowを利用する場合、推論用エンドポイントには[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)が利用されます。推論時に独自の前処理や後処理を実行したい場合は[こちら](https://sagemaker.readthedocs.io/en/stable/using_tf.html#create-python-scripts-for-custom-input-and-output-formats)を参考に推論用のPython Scriptを指定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x117eaae48>: Failed to establish a new connection: [Errno 61] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x117eb8208>: Failed to establish a new connection: [Errno 61] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x117eb8128>: Failed to establish a new connection: [Errno 61] Connection refused',)': /ping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpi6munkgg_algo-1-siciv_1\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:starting services\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:using default model name: model\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:tensorflow serving model config: \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m model_config_list: {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   config: {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     name: \"model\",\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     base_path: \"/opt/ml/model/model\",\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   },\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:nginx config: \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m load_module modules/ngx_http_js_module.so;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m worker_processes auto;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m daemon off;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m error_log  /dev/stderr info;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m events {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m http {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   default_type application/json;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   js_include tensorflow-serving.js;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   upstream tfs_upstream {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     server localhost:8501;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   upstream gunicorn_upstream {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   server {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     client_body_buffer_size 100m;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     subrequest_output_buffer_size 100m;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     set $tfs_version 1.14;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     set $default_tfs_model model;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     location /tfs {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         proxy_redirect off;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         proxy_pass_request_headers off;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         proxy_set_header Content-Type 'application/json';\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         proxy_set_header Accept 'application/json';\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         proxy_pass http://tfs_upstream;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     location /ping {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         js_content ping;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     location /invocations {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     location / {\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:tensorflow version info:\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m TensorFlow ModelServer: 1.14.0-rc0+dev.sha.34d9e855\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m TensorFlow Library: 1.14.0\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:started tensorflow serving (pid: 8)\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:nginx version info:\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m nginx version: nginx/1.16.0\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m built by gcc 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04) \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m built with OpenSSL 1.1.0g  2 Nov 2017 (running with OpenSSL 1.1.1  11 Sep 2018)\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m TLS SNI support enabled\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.16.0/debian/debuild-base/nginx-1.16.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m INFO:__main__:started nginx (pid: 10)\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: using the \"epoll\" event method\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: nginx/1.16.0\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: built by gcc 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04) \n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: OS: Linux 4.9.184-linuxkit\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: start worker processes\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: start worker process 11\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019/11/30 14:51:11 [notice] 10#10: start worker process 12\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.564796: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.564873: I tensorflow_serving/model_servers/server_core.cc:561]  (Re-)adding model: model\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.678697: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.678748: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.678783: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.679433: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:363] Attempting to load native SavedModelBundle in bundle-shim from: /opt/ml/model/model/1\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.679498: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/model/1\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.689303: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.695294: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.724461: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.914257: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 234755 microseconds.\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.916342: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:103] No warmup data file found at /opt/ml/model/model/1/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.929696: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.934409: I tensorflow_serving/model_servers/server.cc:324] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m [evhttp_server.cc : 239] RAW: Entering the event loop ...\n",
      "\u001b[36malgo-1-siciv_1  |\u001b[0m 2019-11-30 14:51:11.937338: I tensorflow_serving/model_servers/server.cc:344] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "!\u001b[36malgo-1-siciv_1  |\u001b[0m 172.22.0.1 - - [30/Nov/2019:14:51:13 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "CPU times: user 365 ms, sys: 226 ms, total: 592 ms\n",
      "Wall time: 7.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "local_predictor = local_estimator.deploy(instance_type='local', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                                                                             COMMAND             CREATED             STATUS              PORTS                                   NAMES\n",
      "1208676c7ac6        763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/tensorflow-inference:1.14-cpu   \"serve\"             3 seconds ago       Up 1 second         0.0.0.0:8080->8080/tcp, 8500-8501/tcp   tmpi6munkgg_algo-1-siciv_1\n"
     ]
    }
   ],
   "source": [
    "# Local modeでdeployした場合、tensorflow-inferenceコンテナが手元の環境に立ち上がるのを確認\n",
    "! docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted labels are: [3 0 5 8 1]\u001b[36malgo-1-siciv_1  |\u001b[0m 172.22.0.1 - - [30/Nov/2019:14:51:44 +0000] \"POST /invocations HTTP/1.1\" 200 817 \"-\" \"-\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 実際にランダムな5個の画像を入力し推論APIの動作を確認\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(x_test.shape[0] - 1), num_samples)\n",
    "images, labels = x_test[indices]/255, y_test[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "prediction = local_predictor.predict(images.reshape(num_samples, 28, 28, 1))['predictions']\n",
    "prediction = np.array(prediction)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('The predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "# Delete endpoint\n",
    "local_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n"
     ]
    }
   ],
   "source": [
    "! docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMakerを利用した学習と推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHubへのpush\n",
    "手元の環境で少量のデータを用いてコードが問題なく動作するかを確認できたので、コードをGitHubにpushします。commitやpushの過程は省略します。Githubを介さずSageMaker学習や推論を行なうことはもちろん可能ですが、今回はGithubを利用する場合の利用法を記しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用データをS3にアップロード\n",
    "SageMaker Python SDKのupload_data関数を利用して、S3へデータをアップロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is uploaded to: s3://sagemaker-ap-northeast-1-219819523389/dataset/mnist\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Session\n",
    "sagemaker_session = Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "input_data = sagemaker_session.upload_data(path='./data', bucket=bucket_name, key_prefix='dataset/mnist')\n",
    "print('Training data is uploaded to: {}'.format(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMakerを利用した学習\n",
    "\n",
    "ローカル環境での学習の際とは異なり、`instance_type`で学習用のインスタンスタイプを指定することで別途SageMakerの学習用インスタンスを起動し学習することができます。学習用インスタンスは学習が終わると自動的に終了するため、大量のデータに対してGPUや多くのCPU・メモリを利用して学習を行う際もコスト効率良く実行することができます。インスタンスタイプの詳細は[こちら](https://aws.amazon.com/jp/sagemaker/pricing/instance-types/)から確認できます。他にも複数ノードによる分散学習については[こちら](https://aws.amazon.com/jp/blogs/news/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/)をご覧ください。\n",
    "\n",
    "git_configパラメータを利用することで、GitHubやCodeCommitで管理されたコードを利用し学習・推論を行なうことができます。具体的にはEstimator作成時にgit_configを指定すると、SageMaker Python SDKがGitHub等からソースコードを手元の環境にcloneし、S3へアップロードした後、学習ジョブ実行時にそのS３パスを引き渡します。git_configの詳細は[こちら](https://sagemaker.readthedocs.io/en/stable/overview.html#use-scripts-stored-in-a-git-repository)をご覧ください。git clone部分でエラーが発生する場合、まずはgitのcredential周りをご確認下さい。\n",
    "\n",
    "roleにはSageMakerの学習用インスタンスが利用するIAM RoleのARNを指定します。詳細は[こちら](https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/sagemaker-roles.html#sagemaker-roles-createtrainingjob-perms)を確認下さい。過去にノートブックインスタンスを立ち上げたことがある場合、そのタイミングで作成されたSageMaker用のIAMロールを利用頂いても大丈夫です(サクッと検証したい場合)。\n",
    "\n",
    "学習が始まると、学習用インスタンスに出力されたログが表示されます。\n",
    "\n",
    "![図2](./images/image2.jpg \"図2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 07:52:21 Starting - Starting the training job...\n",
      "2019-12-01 07:52:22 Starting - Launching requested ML instances......\n",
      "2019-12-01 07:53:24 Starting - Preparing the instances for training...\n",
      "2019-12-01 07:54:17 Downloading - Downloading input data...\n",
      "2019-12-01 07:54:33 Training - Downloading the training image..\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mx_train shape: (60000, 28, 28, 1)\u001b[0m\n",
      "\u001b[34m60000 train samples\u001b[0m\n",
      "\u001b[34m10000 test samples\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW1201 07:55:04.845419 140660131501824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1201 07:55:04.868910 140660131501824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1201 07:55:04.886344 140660131501824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1201 07:55:04.934950 140660131501824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1201 07:55:04.941651 140660131501824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW1201 07:55:05.059250 140660131501824 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mW1201 07:55:05.164807 140660131501824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTrain on 60000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/2\u001b[0m\n",
      "\u001b[34m2019-12-01 07:55:05.512761: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m   64/60000 [..............................] - ETA: 15:50 - loss: 2.4149 - acc: 0.0781\n",
      "  192/60000 [..............................] - ETA: 5:32 - loss: 2.1394 - acc: 0.2135 \n",
      "  384/60000 [..............................] - ETA: 2:55 - loss: 1.9532 - acc: 0.3385\n",
      "  576/60000 [..............................] - ETA: 2:03 - loss: 1.7069 - acc: 0.4271\n",
      "  768/60000 [..............................] - ETA: 1:37 - loss: 1.5487 - acc: 0.4792\n",
      "  896/60000 [..............................] - ETA: 1:26 - loss: 1.4496 - acc: 0.5100\n",
      " 1088/60000 [..............................] - ETA: 1:14 - loss: 1.3018 - acc: 0.5671\n",
      " 1280/60000 [..............................] - ETA: 1:06 - loss: 1.2671 - acc: 0.5789\n",
      " 1472/60000 [..............................] - ETA: 1:00 - loss: 1.1884 - acc: 0.6107\n",
      " 1664/60000 [..............................] - ETA: 55s - loss: 1.1193 - acc: 0.6328 \n",
      " 1856/60000 [..............................] - ETA: 52s - loss: 1.0736 - acc: 0.6471\u001b[0m\n",
      "\u001b[34m 2048/60000 [>.............................] - ETA: 49s - loss: 1.0252 - acc: 0.6670\n",
      " 2240/60000 [>.............................] - ETA: 46s - loss: 0.9795 - acc: 0.6821\n",
      " 2432/60000 [>.............................] - ETA: 44s - loss: 0.9433 - acc: 0.6924\n",
      " 2624/60000 [>.............................] - ETA: 42s - loss: 0.9048 - acc: 0.7081\n",
      " 2752/60000 [>.............................] - ETA: 41s - loss: 0.8803 - acc: 0.7148\n",
      " 2944/60000 [>.............................] - ETA: 40s - loss: 0.8511 - acc: 0.7262\n",
      " 3136/60000 [>.............................] - ETA: 38s - loss: 0.8218 - acc: 0.7372\n",
      " 3328/60000 [>.............................] - ETA: 37s - loss: 0.7970 - acc: 0.7446\n",
      " 3456/60000 [>.............................] - ETA: 37s - loss: 0.7854 - acc: 0.7486\n",
      " 3648/60000 [>.............................] - ETA: 36s - loss: 0.7673 - acc: 0.7525\n",
      " 3840/60000 [>.............................] - ETA: 35s - loss: 0.7474 - acc: 0.7599\n",
      " 4032/60000 [=>............................] - ETA: 34s - loss: 0.7368 - acc: 0.7631\n",
      " 4160/60000 [=>............................] - ETA: 34s - loss: 0.7227 - acc: 0.7673\n",
      " 4352/60000 [=>............................] - ETA: 33s - loss: 0.7078 - acc: 0.7730\u001b[0m\n",
      "\u001b[34m 4544/60000 [=>............................] - ETA: 32s - loss: 0.6927 - acc: 0.7782\n",
      " 4736/60000 [=>............................] - ETA: 32s - loss: 0.6808 - acc: 0.7829\n",
      " 4864/60000 [=>............................] - ETA: 31s - loss: 0.6776 - acc: 0.7841\n",
      " 5056/60000 [=>............................] - ETA: 31s - loss: 0.6665 - acc: 0.7894\n",
      " 5248/60000 [=>............................] - ETA: 30s - loss: 0.6534 - acc: 0.7944\n",
      " 5440/60000 [=>............................] - ETA: 30s - loss: 0.6412 - acc: 0.7985\n",
      " 5632/60000 [=>............................] - ETA: 29s - loss: 0.6309 - acc: 0.8017\n",
      " 5824/60000 [=>............................] - ETA: 29s - loss: 0.6196 - acc: 0.8049\n",
      " 6016/60000 [==>...........................] - ETA: 28s - loss: 0.6085 - acc: 0.8093\n",
      " 6208/60000 [==>...........................] - ETA: 28s - loss: 0.5998 - acc: 0.8127\n",
      " 6336/60000 [==>...........................] - ETA: 28s - loss: 0.5946 - acc: 0.8142\n",
      " 6528/60000 [==>...........................] - ETA: 27s - loss: 0.5849 - acc: 0.8177\n",
      " 6720/60000 [==>...........................] - ETA: 27s - loss: 0.5755 - acc: 0.8204\n",
      " 6912/60000 [==>...........................] - ETA: 27s - loss: 0.5650 - acc: 0.8236\n",
      " 7040/60000 [==>...........................] - ETA: 27s - loss: 0.5623 - acc: 0.8250\n",
      " 7232/60000 [==>...........................] - ETA: 26s - loss: 0.5565 - acc: 0.8266\u001b[0m\n",
      "\u001b[34m 7424/60000 [==>...........................] - ETA: 26s - loss: 0.5483 - acc: 0.8292\n",
      " 7616/60000 [==>...........................] - ETA: 26s - loss: 0.5405 - acc: 0.8317\n",
      " 7808/60000 [==>...........................] - ETA: 25s - loss: 0.5359 - acc: 0.8327\n",
      " 8000/60000 [===>..........................] - ETA: 25s - loss: 0.5317 - acc: 0.8343\n",
      " 8192/60000 [===>..........................] - ETA: 25s - loss: 0.5260 - acc: 0.8363\n",
      " 8384/60000 [===>..........................] - ETA: 25s - loss: 0.5201 - acc: 0.8386\n",
      " 8576/60000 [===>..........................] - ETA: 24s - loss: 0.5159 - acc: 0.8398\n",
      " 8768/60000 [===>..........................] - ETA: 24s - loss: 0.5101 - acc: 0.8416\n",
      " 8960/60000 [===>..........................] - ETA: 24s - loss: 0.5029 - acc: 0.8436\n",
      " 9152/60000 [===>..........................] - ETA: 24s - loss: 0.5042 - acc: 0.8436\n",
      " 9344/60000 [===>..........................] - ETA: 23s - loss: 0.4990 - acc: 0.8449\n",
      " 9536/60000 [===>..........................] - ETA: 23s - loss: 0.4937 - acc: 0.8464\n",
      " 9728/60000 [===>..........................] - ETA: 23s - loss: 0.4892 - acc: 0.8482\n",
      " 9920/60000 [===>..........................] - ETA: 23s - loss: 0.4839 - acc: 0.8497\u001b[0m\n",
      "\n",
      "2019-12-01 07:54:57 Training - Training image download completed. Training in progress.\u001b[34m10112/60000 [====>.........................] - ETA: 23s - loss: 0.4804 - acc: 0.8510\u001b[0m\n",
      "\u001b[34m10304/60000 [====>.........................] - ETA: 22s - loss: 0.4745 - acc: 0.8528\u001b[0m\n",
      "\u001b[34m10496/60000 [====>.........................] - ETA: 22s - loss: 0.4700 - acc: 0.8542\u001b[0m\n",
      "\u001b[34m10688/60000 [====>.........................] - ETA: 22s - loss: 0.4658 - acc: 0.8556\u001b[0m\n",
      "\u001b[34m10880/60000 [====>.........................] - ETA: 22s - loss: 0.4605 - acc: 0.8574\u001b[0m\n",
      "\u001b[34m11072/60000 [====>.........................] - ETA: 22s - loss: 0.4558 - acc: 0.8587\u001b[0m\n",
      "\u001b[34m11264/60000 [====>.........................] - ETA: 22s - loss: 0.4511 - acc: 0.8604\u001b[0m\n",
      "\u001b[34m11456/60000 [====>.........................] - ETA: 21s - loss: 0.4472 - acc: 0.8618\u001b[0m\n",
      "\u001b[34m11648/60000 [====>.........................] - ETA: 21s - loss: 0.4435 - acc: 0.8628\u001b[0m\n",
      "\u001b[34m11840/60000 [====>.........................] - ETA: 21s - loss: 0.4391 - acc: 0.8643\u001b[0m\n",
      "\u001b[34m11968/60000 [====>.........................] - ETA: 21s - loss: 0.4375 - acc: 0.8646\u001b[0m\n",
      "\u001b[34m12096/60000 [=====>........................] - ETA: 21s - loss: 0.4362 - acc: 0.8650\u001b[0m\n",
      "\u001b[34m12288/60000 [=====>........................] - ETA: 21s - loss: 0.4328 - acc: 0.8659\u001b[0m\n",
      "\u001b[34m12480/60000 [=====>........................] - ETA: 21s - loss: 0.4300 - acc: 0.8667\u001b[0m\n",
      "\u001b[34m12672/60000 [=====>........................] - ETA: 20s - loss: 0.4274 - acc: 0.8674\u001b[0m\n",
      "\u001b[34m12864/60000 [=====>........................] - ETA: 20s - loss: 0.4250 - acc: 0.8682\u001b[0m\n",
      "\u001b[34m13056/60000 [=====>........................] - ETA: 20s - loss: 0.4218 - acc: 0.8694\u001b[0m\n",
      "\u001b[34m13248/60000 [=====>........................] - ETA: 20s - loss: 0.4202 - acc: 0.8700\u001b[0m\n",
      "\u001b[34m13440/60000 [=====>........................] - ETA: 20s - loss: 0.4176 - acc: 0.8708\u001b[0m\n",
      "\u001b[34m13632/60000 [=====>........................] - ETA: 20s - loss: 0.4162 - acc: 0.8713\u001b[0m\n",
      "\u001b[34m13824/60000 [=====>........................] - ETA: 20s - loss: 0.4134 - acc: 0.8720\u001b[0m\n",
      "\u001b[34m14016/60000 [======>.......................] - ETA: 19s - loss: 0.4108 - acc: 0.8726\u001b[0m\n",
      "\u001b[34m14208/60000 [======>.......................] - ETA: 19s - loss: 0.4088 - acc: 0.8735\u001b[0m\n",
      "\u001b[34m14400/60000 [======>.......................] - ETA: 19s - loss: 0.4051 - acc: 0.8747\u001b[0m\n",
      "\u001b[34m14592/60000 [======>.......................] - ETA: 19s - loss: 0.4037 - acc: 0.8753\u001b[0m\n",
      "\u001b[34m14784/60000 [======>.......................] - ETA: 19s - loss: 0.4030 - acc: 0.8755\u001b[0m\n",
      "\u001b[34m14976/60000 [======>.......................] - ETA: 19s - loss: 0.4034 - acc: 0.8753\u001b[0m\n",
      "\u001b[34m15168/60000 [======>.......................] - ETA: 19s - loss: 0.4007 - acc: 0.8763\u001b[0m\n",
      "\u001b[34m15360/60000 [======>.......................] - ETA: 19s - loss: 0.3990 - acc: 0.8768\u001b[0m\n",
      "\u001b[34m15552/60000 [======>.......................] - ETA: 18s - loss: 0.3970 - acc: 0.8776\u001b[0m\n",
      "\u001b[34m15744/60000 [======>.......................] - ETA: 18s - loss: 0.3951 - acc: 0.8782\u001b[0m\n",
      "\u001b[34m15936/60000 [======>.......................] - ETA: 18s - loss: 0.3928 - acc: 0.8790\u001b[0m\n",
      "\u001b[34m16128/60000 [=======>......................] - ETA: 18s - loss: 0.3901 - acc: 0.8798\u001b[0m\n",
      "\u001b[34m16320/60000 [=======>......................] - ETA: 18s - loss: 0.3877 - acc: 0.8806\u001b[0m\n",
      "\u001b[34m16512/60000 [=======>......................] - ETA: 18s - loss: 0.3851 - acc: 0.8815\u001b[0m\n",
      "\u001b[34m16704/60000 [=======>......................] - ETA: 18s - loss: 0.3828 - acc: 0.8823\u001b[0m\n",
      "\u001b[34m16896/60000 [=======>......................] - ETA: 18s - loss: 0.3806 - acc: 0.8828\u001b[0m\n",
      "\u001b[34m17088/60000 [=======>......................] - ETA: 18s - loss: 0.3783 - acc: 0.8834\u001b[0m\n",
      "\u001b[34m17280/60000 [=======>......................] - ETA: 17s - loss: 0.3757 - acc: 0.8843\u001b[0m\n",
      "\u001b[34m17472/60000 [=======>......................] - ETA: 17s - loss: 0.3733 - acc: 0.8851\u001b[0m\n",
      "\u001b[34m17664/60000 [=======>......................] - ETA: 17s - loss: 0.3716 - acc: 0.8856\u001b[0m\n",
      "\u001b[34m17856/60000 [=======>......................] - ETA: 17s - loss: 0.3704 - acc: 0.8858\u001b[0m\n",
      "\u001b[34m18048/60000 [========>.....................] - ETA: 17s - loss: 0.3691 - acc: 0.8862\u001b[0m\n",
      "\u001b[34m18240/60000 [========>.....................] - ETA: 17s - loss: 0.3670 - acc: 0.8869\u001b[0m\n",
      "\u001b[34m18368/60000 [========>.....................] - ETA: 17s - loss: 0.3653 - acc: 0.8874\u001b[0m\n",
      "\u001b[34m18560/60000 [========>.....................] - ETA: 17s - loss: 0.3640 - acc: 0.8878\u001b[0m\n",
      "\u001b[34m18752/60000 [========>.....................] - ETA: 17s - loss: 0.3621 - acc: 0.8884\u001b[0m\n",
      "\u001b[34m18944/60000 [========>.....................] - ETA: 17s - loss: 0.3599 - acc: 0.8891\u001b[0m\n",
      "\u001b[34m19136/60000 [========>.....................] - ETA: 16s - loss: 0.3584 - acc: 0.8895\u001b[0m\n",
      "\u001b[34m19328/60000 [========>.....................] - ETA: 16s - loss: 0.3567 - acc: 0.8901\u001b[0m\n",
      "\u001b[34m19520/60000 [========>.....................] - ETA: 16s - loss: 0.3554 - acc: 0.8904\u001b[0m\n",
      "\u001b[34m19648/60000 [========>.....................] - ETA: 16s - loss: 0.3539 - acc: 0.8908\u001b[0m\n",
      "\u001b[34m19840/60000 [========>.....................] - ETA: 16s - loss: 0.3523 - acc: 0.8913\u001b[0m\n",
      "\u001b[34m20032/60000 [=========>....................] - ETA: 16s - loss: 0.3501 - acc: 0.8919\u001b[0m\n",
      "\u001b[34m20224/60000 [=========>....................] - ETA: 16s - loss: 0.3490 - acc: 0.8921\u001b[0m\n",
      "\u001b[34m20352/60000 [=========>....................] - ETA: 16s - loss: 0.3481 - acc: 0.8925\u001b[0m\n",
      "\u001b[34m20544/60000 [=========>....................] - ETA: 16s - loss: 0.3458 - acc: 0.8931\u001b[0m\n",
      "\u001b[34m20736/60000 [=========>....................] - ETA: 16s - loss: 0.3439 - acc: 0.8937\u001b[0m\n",
      "\u001b[34m20928/60000 [=========>....................] - ETA: 16s - loss: 0.3422 - acc: 0.8941\u001b[0m\n",
      "\u001b[34m21120/60000 [=========>....................] - ETA: 15s - loss: 0.3413 - acc: 0.8945\u001b[0m\n",
      "\u001b[34m21312/60000 [=========>....................] - ETA: 15s - loss: 0.3399 - acc: 0.8949\u001b[0m\n",
      "\u001b[34m21504/60000 [=========>....................] - ETA: 15s - loss: 0.3393 - acc: 0.8952\u001b[0m\n",
      "\u001b[34m21696/60000 [=========>....................] - ETA: 15s - loss: 0.3371 - acc: 0.8959\u001b[0m\n",
      "\u001b[34m21888/60000 [=========>....................] - ETA: 15s - loss: 0.3355 - acc: 0.8964\u001b[0m\n",
      "\u001b[34m22080/60000 [==========>...................] - ETA: 15s - loss: 0.3336 - acc: 0.8970\u001b[0m\n",
      "\u001b[34m22272/60000 [==========>...................] - ETA: 15s - loss: 0.3316 - acc: 0.8977\u001b[0m\n",
      "\u001b[34m22464/60000 [==========>...................] - ETA: 15s - loss: 0.3296 - acc: 0.8984\u001b[0m\n",
      "\u001b[34m22656/60000 [==========>...................] - ETA: 15s - loss: 0.3285 - acc: 0.8987\u001b[0m\n",
      "\u001b[34m22848/60000 [==========>...................] - ETA: 15s - loss: 0.3274 - acc: 0.8990\u001b[0m\n",
      "\u001b[34m23040/60000 [==========>...................] - ETA: 14s - loss: 0.3257 - acc: 0.8996\u001b[0m\n",
      "\u001b[34m23232/60000 [==========>...................] - ETA: 14s - loss: 0.3247 - acc: 0.8999\u001b[0m\n",
      "\u001b[34m23424/60000 [==========>...................] - ETA: 14s - loss: 0.3230 - acc: 0.9004\u001b[0m\n",
      "\u001b[34m23616/60000 [==========>...................] - ETA: 14s - loss: 0.3215 - acc: 0.9009\u001b[0m\n",
      "\u001b[34m23808/60000 [==========>...................] - ETA: 14s - loss: 0.3200 - acc: 0.9013\u001b[0m\n",
      "\u001b[34m24000/60000 [===========>..................] - ETA: 14s - loss: 0.3181 - acc: 0.9019\u001b[0m\n",
      "\u001b[34m24192/60000 [===========>..................] - ETA: 14s - loss: 0.3167 - acc: 0.9024\u001b[0m\n",
      "\u001b[34m24384/60000 [===========>..................] - ETA: 14s - loss: 0.3151 - acc: 0.9030\u001b[0m\n",
      "\u001b[34m24576/60000 [===========>..................] - ETA: 14s - loss: 0.3136 - acc: 0.9034\u001b[0m\n",
      "\u001b[34m24768/60000 [===========>..................] - ETA: 14s - loss: 0.3128 - acc: 0.9037\u001b[0m\n",
      "\u001b[34m24960/60000 [===========>..................] - ETA: 14s - loss: 0.3120 - acc: 0.9040\u001b[0m\n",
      "\u001b[34m25152/60000 [===========>..................] - ETA: 13s - loss: 0.3112 - acc: 0.9044\u001b[0m\n",
      "\u001b[34m25280/60000 [===========>..................] - ETA: 13s - loss: 0.3109 - acc: 0.9045\u001b[0m\n",
      "\u001b[34m25472/60000 [===========>..................] - ETA: 13s - loss: 0.3097 - acc: 0.9050\u001b[0m\n",
      "\u001b[34m25664/60000 [===========>..................] - ETA: 13s - loss: 0.3083 - acc: 0.9054\u001b[0m\n",
      "\u001b[34m25856/60000 [===========>..................] - ETA: 13s - loss: 0.3069 - acc: 0.9059\u001b[0m\n",
      "\u001b[34m26048/60000 [============>.................] - ETA: 13s - loss: 0.3058 - acc: 0.9063\u001b[0m\n",
      "\u001b[34m26240/60000 [============>.................] - ETA: 13s - loss: 0.3041 - acc: 0.9068\u001b[0m\n",
      "\u001b[34m26432/60000 [============>.................] - ETA: 13s - loss: 0.3034 - acc: 0.9071\u001b[0m\n",
      "\u001b[34m26624/60000 [============>.................] - ETA: 13s - loss: 0.3028 - acc: 0.9074\u001b[0m\n",
      "\u001b[34m26816/60000 [============>.................] - ETA: 13s - loss: 0.3014 - acc: 0.9077\u001b[0m\n",
      "\u001b[34m27008/60000 [============>.................] - ETA: 13s - loss: 0.3006 - acc: 0.9081\u001b[0m\n",
      "\u001b[34m27200/60000 [============>.................] - ETA: 13s - loss: 0.2992 - acc: 0.9085\u001b[0m\n",
      "\u001b[34m27392/60000 [============>.................] - ETA: 12s - loss: 0.2978 - acc: 0.9090\u001b[0m\n",
      "\u001b[34m27584/60000 [============>.................] - ETA: 12s - loss: 0.2967 - acc: 0.9093\u001b[0m\n",
      "\u001b[34m27776/60000 [============>.................] - ETA: 12s - loss: 0.2960 - acc: 0.9096\u001b[0m\n",
      "\u001b[34m27968/60000 [============>.................] - ETA: 12s - loss: 0.2956 - acc: 0.9098\u001b[0m\n",
      "\u001b[34m28160/60000 [=============>................] - ETA: 12s - loss: 0.2946 - acc: 0.9101\u001b[0m\n",
      "\u001b[34m28352/60000 [=============>................] - ETA: 12s - loss: 0.2943 - acc: 0.9102\u001b[0m\n",
      "\u001b[34m28544/60000 [=============>................] - ETA: 12s - loss: 0.2932 - acc: 0.9104\u001b[0m\n",
      "\u001b[34m28736/60000 [=============>................] - ETA: 12s - loss: 0.2920 - acc: 0.9109\u001b[0m\n",
      "\u001b[34m28928/60000 [=============>................] - ETA: 12s - loss: 0.2910 - acc: 0.9112\u001b[0m\n",
      "\u001b[34m29120/60000 [=============>................] - ETA: 12s - loss: 0.2899 - acc: 0.9114\u001b[0m\n",
      "\u001b[34m29312/60000 [=============>................] - ETA: 12s - loss: 0.2891 - acc: 0.9117\u001b[0m\n",
      "\u001b[34m29504/60000 [=============>................] - ETA: 12s - loss: 0.2882 - acc: 0.9119\u001b[0m\n",
      "\u001b[34m29696/60000 [=============>................] - ETA: 11s - loss: 0.2873 - acc: 0.9121\u001b[0m\n",
      "\u001b[34m29888/60000 [=============>................] - ETA: 11s - loss: 0.2861 - acc: 0.9125\u001b[0m\n",
      "\u001b[34m30080/60000 [==============>...............] - ETA: 11s - loss: 0.2847 - acc: 0.9130\u001b[0m\n",
      "\u001b[34m30272/60000 [==============>...............] - ETA: 11s - loss: 0.2837 - acc: 0.9133\u001b[0m\n",
      "\u001b[34m30464/60000 [==============>...............] - ETA: 11s - loss: 0.2833 - acc: 0.9135\u001b[0m\n",
      "\u001b[34m30656/60000 [==============>...............] - ETA: 11s - loss: 0.2824 - acc: 0.9138\u001b[0m\n",
      "\u001b[34m30848/60000 [==============>...............] - ETA: 11s - loss: 0.2815 - acc: 0.9140\u001b[0m\n",
      "\u001b[34m31040/60000 [==============>...............] - ETA: 11s - loss: 0.2805 - acc: 0.9142\u001b[0m\n",
      "\u001b[34m31232/60000 [==============>...............] - ETA: 11s - loss: 0.2800 - acc: 0.9145\u001b[0m\n",
      "\u001b[34m31424/60000 [==============>...............] - ETA: 11s - loss: 0.2790 - acc: 0.9148\u001b[0m\n",
      "\u001b[34m31616/60000 [==============>...............] - ETA: 11s - loss: 0.2779 - acc: 0.9152\u001b[0m\n",
      "\u001b[34m31808/60000 [==============>...............] - ETA: 11s - loss: 0.2778 - acc: 0.9153\u001b[0m\n",
      "\u001b[34m32000/60000 [===============>..............] - ETA: 10s - loss: 0.2773 - acc: 0.9154\u001b[0m\n",
      "\u001b[34m32192/60000 [===============>..............] - ETA: 10s - loss: 0.2765 - acc: 0.9156\u001b[0m\n",
      "\u001b[34m32384/60000 [===============>..............] - ETA: 10s - loss: 0.2757 - acc: 0.9158\u001b[0m\n",
      "\u001b[34m32512/60000 [===============>..............] - ETA: 10s - loss: 0.2751 - acc: 0.9160\u001b[0m\n",
      "\u001b[34m32704/60000 [===============>..............] - ETA: 10s - loss: 0.2743 - acc: 0.9162\u001b[0m\n",
      "\u001b[34m32896/60000 [===============>..............] - ETA: 10s - loss: 0.2742 - acc: 0.9162\u001b[0m\n",
      "\u001b[34m33088/60000 [===============>..............] - ETA: 10s - loss: 0.2738 - acc: 0.9163\u001b[0m\n",
      "\u001b[34m33280/60000 [===============>..............] - ETA: 10s - loss: 0.2729 - acc: 0.9166\u001b[0m\n",
      "\u001b[34m33472/60000 [===============>..............] - ETA: 10s - loss: 0.2720 - acc: 0.9169\u001b[0m\n",
      "\u001b[34m33664/60000 [===============>..............] - ETA: 10s - loss: 0.2714 - acc: 0.9169\u001b[0m\n",
      "\u001b[34m33856/60000 [===============>..............] - ETA: 10s - loss: 0.2704 - acc: 0.9172\u001b[0m\n",
      "\u001b[34m34048/60000 [================>.............] - ETA: 10s - loss: 0.2693 - acc: 0.9176\u001b[0m\n",
      "\u001b[34m34240/60000 [================>.............] - ETA: 10s - loss: 0.2688 - acc: 0.9178\u001b[0m\n",
      "\u001b[34m34432/60000 [================>.............] - ETA: 9s - loss: 0.2678 - acc: 0.9180 \u001b[0m\n",
      "\u001b[34m34560/60000 [================>.............] - ETA: 9s - loss: 0.2672 - acc: 0.9182\u001b[0m\n",
      "\u001b[34m34752/60000 [================>.............] - ETA: 9s - loss: 0.2666 - acc: 0.9183\u001b[0m\n",
      "\u001b[34m34944/60000 [================>.............] - ETA: 9s - loss: 0.2663 - acc: 0.9185\u001b[0m\n",
      "\u001b[34m35136/60000 [================>.............] - ETA: 9s - loss: 0.2658 - acc: 0.9185\u001b[0m\n",
      "\u001b[34m35328/60000 [================>.............] - ETA: 9s - loss: 0.2650 - acc: 0.9188\u001b[0m\n",
      "\u001b[34m35520/60000 [================>.............] - ETA: 9s - loss: 0.2647 - acc: 0.9189\u001b[0m\n",
      "\u001b[34m35712/60000 [================>.............] - ETA: 9s - loss: 0.2646 - acc: 0.9191\u001b[0m\n",
      "\u001b[34m35904/60000 [================>.............] - ETA: 9s - loss: 0.2637 - acc: 0.9193\u001b[0m\n",
      "\u001b[34m36096/60000 [=================>............] - ETA: 9s - loss: 0.2629 - acc: 0.9196\u001b[0m\n",
      "\u001b[34m36288/60000 [=================>............] - ETA: 9s - loss: 0.2621 - acc: 0.9198\u001b[0m\n",
      "\u001b[34m36480/60000 [=================>............] - ETA: 9s - loss: 0.2611 - acc: 0.9201\u001b[0m\n",
      "\u001b[34m36672/60000 [=================>............] - ETA: 9s - loss: 0.2605 - acc: 0.9202\u001b[0m\n",
      "\u001b[34m36864/60000 [=================>............] - ETA: 8s - loss: 0.2596 - acc: 0.9205\u001b[0m\n",
      "\u001b[34m37056/60000 [=================>............] - ETA: 8s - loss: 0.2590 - acc: 0.9205\u001b[0m\n",
      "\u001b[34m37248/60000 [=================>............] - ETA: 8s - loss: 0.2582 - acc: 0.9207\u001b[0m\n",
      "\u001b[34m37440/60000 [=================>............] - ETA: 8s - loss: 0.2572 - acc: 0.9211\u001b[0m\n",
      "\u001b[34m37632/60000 [=================>............] - ETA: 8s - loss: 0.2561 - acc: 0.9214\u001b[0m\n",
      "\u001b[34m37824/60000 [=================>............] - ETA: 8s - loss: 0.2555 - acc: 0.9216\u001b[0m\n",
      "\u001b[34m38016/60000 [==================>...........] - ETA: 8s - loss: 0.2549 - acc: 0.9218\u001b[0m\n",
      "\u001b[34m38208/60000 [==================>...........] - ETA: 8s - loss: 0.2549 - acc: 0.9219\u001b[0m\n",
      "\u001b[34m38400/60000 [==================>...........] - ETA: 8s - loss: 0.2542 - acc: 0.9222\u001b[0m\n",
      "\u001b[34m38592/60000 [==================>...........] - ETA: 8s - loss: 0.2534 - acc: 0.9224\u001b[0m\n",
      "\u001b[34m38784/60000 [==================>...........] - ETA: 8s - loss: 0.2528 - acc: 0.9226\u001b[0m\n",
      "\u001b[34m38976/60000 [==================>...........] - ETA: 8s - loss: 0.2524 - acc: 0.9226\u001b[0m\n",
      "\u001b[34m39168/60000 [==================>...........] - ETA: 8s - loss: 0.2518 - acc: 0.9229\u001b[0m\n",
      "\u001b[34m39360/60000 [==================>...........] - ETA: 7s - loss: 0.2511 - acc: 0.9231\u001b[0m\n",
      "\u001b[34m39552/60000 [==================>...........] - ETA: 7s - loss: 0.2504 - acc: 0.9233\u001b[0m\n",
      "\u001b[34m39744/60000 [==================>...........] - ETA: 7s - loss: 0.2500 - acc: 0.9234\u001b[0m\n",
      "\u001b[34m39936/60000 [==================>...........] - ETA: 7s - loss: 0.2493 - acc: 0.9236\u001b[0m\n",
      "\u001b[34m40128/60000 [===================>..........] - ETA: 7s - loss: 0.2486 - acc: 0.9238\u001b[0m\n",
      "\u001b[34m40320/60000 [===================>..........] - ETA: 7s - loss: 0.2478 - acc: 0.9241\u001b[0m\n",
      "\u001b[34m40512/60000 [===================>..........] - ETA: 7s - loss: 0.2473 - acc: 0.9243\u001b[0m\n",
      "\u001b[34m40704/60000 [===================>..........] - ETA: 7s - loss: 0.2464 - acc: 0.9245\u001b[0m\n",
      "\u001b[34m40896/60000 [===================>..........] - ETA: 7s - loss: 0.2459 - acc: 0.9247\u001b[0m\n",
      "\u001b[34m41088/60000 [===================>..........] - ETA: 7s - loss: 0.2453 - acc: 0.9248\u001b[0m\n",
      "\u001b[34m41280/60000 [===================>..........] - ETA: 7s - loss: 0.2445 - acc: 0.9250\u001b[0m\n",
      "\u001b[34m41472/60000 [===================>..........] - ETA: 7s - loss: 0.2438 - acc: 0.9253\u001b[0m\n",
      "\u001b[34m41664/60000 [===================>..........] - ETA: 6s - loss: 0.2437 - acc: 0.9253\u001b[0m\n",
      "\u001b[34m41856/60000 [===================>..........] - ETA: 6s - loss: 0.2433 - acc: 0.9255\u001b[0m\n",
      "\u001b[34m42048/60000 [====================>.........] - ETA: 6s - loss: 0.2426 - acc: 0.9257\u001b[0m\n",
      "\u001b[34m42240/60000 [====================>.........] - ETA: 6s - loss: 0.2418 - acc: 0.9259\u001b[0m\n",
      "\u001b[34m42432/60000 [====================>.........] - ETA: 6s - loss: 0.2412 - acc: 0.9261\u001b[0m\n",
      "\u001b[34m42624/60000 [====================>.........] - ETA: 6s - loss: 0.2407 - acc: 0.9263\u001b[0m\n",
      "\u001b[34m42816/60000 [====================>.........] - ETA: 6s - loss: 0.2399 - acc: 0.9265\u001b[0m\n",
      "\u001b[34m43008/60000 [====================>.........] - ETA: 6s - loss: 0.2392 - acc: 0.9267\u001b[0m\n",
      "\u001b[34m43200/60000 [====================>.........] - ETA: 6s - loss: 0.2385 - acc: 0.9268\u001b[0m\n",
      "\u001b[34m43392/60000 [====================>.........] - ETA: 6s - loss: 0.2377 - acc: 0.9270\u001b[0m\n",
      "\u001b[34m43584/60000 [====================>.........] - ETA: 6s - loss: 0.2371 - acc: 0.9273\u001b[0m\n",
      "\u001b[34m43776/60000 [====================>.........] - ETA: 6s - loss: 0.2363 - acc: 0.9275\u001b[0m\n",
      "\u001b[34m43968/60000 [====================>.........] - ETA: 6s - loss: 0.2359 - acc: 0.9276\u001b[0m\n",
      "\u001b[34m44160/60000 [=====================>........] - ETA: 6s - loss: 0.2351 - acc: 0.9279\u001b[0m\n",
      "\u001b[34m44352/60000 [=====================>........] - ETA: 5s - loss: 0.2346 - acc: 0.9281\u001b[0m\n",
      "\u001b[34m44544/60000 [=====================>........] - ETA: 5s - loss: 0.2340 - acc: 0.9283\u001b[0m\n",
      "\u001b[34m44736/60000 [=====================>........] - ETA: 5s - loss: 0.2336 - acc: 0.9283\u001b[0m\n",
      "\u001b[34m44928/60000 [=====================>........] - ETA: 5s - loss: 0.2332 - acc: 0.9285\u001b[0m\n",
      "\u001b[34m45120/60000 [=====================>........] - ETA: 5s - loss: 0.2328 - acc: 0.9286\u001b[0m\n",
      "\u001b[34m45312/60000 [=====================>........] - ETA: 5s - loss: 0.2325 - acc: 0.9287\u001b[0m\n",
      "\u001b[34m45504/60000 [=====================>........] - ETA: 5s - loss: 0.2317 - acc: 0.9289\u001b[0m\n",
      "\u001b[34m45696/60000 [=====================>........] - ETA: 5s - loss: 0.2313 - acc: 0.9291\u001b[0m\n",
      "\u001b[34m45888/60000 [=====================>........] - ETA: 5s - loss: 0.2311 - acc: 0.9292\u001b[0m\n",
      "\u001b[34m46080/60000 [======================>.......] - ETA: 5s - loss: 0.2305 - acc: 0.9294\u001b[0m\n",
      "\u001b[34m46208/60000 [======================>.......] - ETA: 5s - loss: 0.2301 - acc: 0.9294\u001b[0m\n",
      "\u001b[34m46400/60000 [======================>.......] - ETA: 5s - loss: 0.2300 - acc: 0.9295\u001b[0m\n",
      "\u001b[34m46592/60000 [======================>.......] - ETA: 5s - loss: 0.2296 - acc: 0.9296\u001b[0m\n",
      "\u001b[34m46784/60000 [======================>.......] - ETA: 5s - loss: 0.2294 - acc: 0.9297\u001b[0m\n",
      "\u001b[34m46912/60000 [======================>.......] - ETA: 4s - loss: 0.2291 - acc: 0.9298\u001b[0m\n",
      "\u001b[34m47104/60000 [======================>.......] - ETA: 4s - loss: 0.2291 - acc: 0.9299\u001b[0m\n",
      "\u001b[34m47296/60000 [======================>.......] - ETA: 4s - loss: 0.2286 - acc: 0.9300\u001b[0m\n",
      "\u001b[34m47488/60000 [======================>.......] - ETA: 4s - loss: 0.2282 - acc: 0.9302\u001b[0m\n",
      "\u001b[34m47680/60000 [======================>.......] - ETA: 4s - loss: 0.2279 - acc: 0.9302\u001b[0m\n",
      "\u001b[34m47872/60000 [======================>.......] - ETA: 4s - loss: 0.2271 - acc: 0.9305\u001b[0m\n",
      "\u001b[34m48064/60000 [=======================>......] - ETA: 4s - loss: 0.2265 - acc: 0.9307\u001b[0m\n",
      "\u001b[34m48256/60000 [=======================>......] - ETA: 4s - loss: 0.2258 - acc: 0.9309\u001b[0m\n",
      "\u001b[34m48448/60000 [=======================>......] - ETA: 4s - loss: 0.2253 - acc: 0.9310\u001b[0m\n",
      "\u001b[34m48640/60000 [=======================>......] - ETA: 4s - loss: 0.2250 - acc: 0.9311\u001b[0m\n",
      "\u001b[34m48832/60000 [=======================>......] - ETA: 4s - loss: 0.2244 - acc: 0.9313\u001b[0m\n",
      "\u001b[34m48960/60000 [=======================>......] - ETA: 4s - loss: 0.2240 - acc: 0.9314\u001b[0m\n",
      "\u001b[34m49152/60000 [=======================>......] - ETA: 4s - loss: 0.2237 - acc: 0.9315\u001b[0m\n",
      "\u001b[34m49344/60000 [=======================>......] - ETA: 4s - loss: 0.2236 - acc: 0.9315\u001b[0m\n",
      "\u001b[34m49536/60000 [=======================>......] - ETA: 3s - loss: 0.2231 - acc: 0.9317\u001b[0m\n",
      "\u001b[34m49728/60000 [=======================>......] - ETA: 3s - loss: 0.2227 - acc: 0.9318\u001b[0m\n",
      "\u001b[34m49920/60000 [=======================>......] - ETA: 3s - loss: 0.2223 - acc: 0.9319\u001b[0m\n",
      "\u001b[34m50112/60000 [========================>.....] - ETA: 3s - loss: 0.2220 - acc: 0.9319\u001b[0m\n",
      "\u001b[34m50304/60000 [========================>.....] - ETA: 3s - loss: 0.2217 - acc: 0.9321\u001b[0m\n",
      "\u001b[34m50496/60000 [========================>.....] - ETA: 3s - loss: 0.2214 - acc: 0.9322\u001b[0m\n",
      "\u001b[34m50688/60000 [========================>.....] - ETA: 3s - loss: 0.2208 - acc: 0.9323\u001b[0m\n",
      "\u001b[34m50816/60000 [========================>.....] - ETA: 3s - loss: 0.2206 - acc: 0.9324\u001b[0m\n",
      "\u001b[34m51008/60000 [========================>.....] - ETA: 3s - loss: 0.2202 - acc: 0.9325\u001b[0m\n",
      "\u001b[34m51200/60000 [========================>.....] - ETA: 3s - loss: 0.2197 - acc: 0.9327\u001b[0m\n",
      "\u001b[34m51392/60000 [========================>.....] - ETA: 3s - loss: 0.2194 - acc: 0.9328\u001b[0m\n",
      "\u001b[34m51584/60000 [========================>.....] - ETA: 3s - loss: 0.2189 - acc: 0.9330\u001b[0m\n",
      "\u001b[34m51776/60000 [========================>.....] - ETA: 3s - loss: 0.2185 - acc: 0.9331\u001b[0m\n",
      "\u001b[34m51968/60000 [========================>.....] - ETA: 3s - loss: 0.2184 - acc: 0.9332\u001b[0m\n",
      "\u001b[34m52160/60000 [=========================>....] - ETA: 2s - loss: 0.2178 - acc: 0.9333\u001b[0m\n",
      "\u001b[34m52352/60000 [=========================>....] - ETA: 2s - loss: 0.2174 - acc: 0.9335\u001b[0m\n",
      "\u001b[34m52544/60000 [=========================>....] - ETA: 2s - loss: 0.2168 - acc: 0.9337\u001b[0m\n",
      "\u001b[34m52736/60000 [=========================>....] - ETA: 2s - loss: 0.2166 - acc: 0.9338\u001b[0m\n",
      "\u001b[34m52928/60000 [=========================>....] - ETA: 2s - loss: 0.2164 - acc: 0.9338\u001b[0m\n",
      "\u001b[34m53120/60000 [=========================>....] - ETA: 2s - loss: 0.2160 - acc: 0.9340\u001b[0m\n",
      "\u001b[34m53312/60000 [=========================>....] - ETA: 2s - loss: 0.2156 - acc: 0.9340\u001b[0m\n",
      "\u001b[34m53504/60000 [=========================>....] - ETA: 2s - loss: 0.2153 - acc: 0.9342\u001b[0m\n",
      "\u001b[34m53696/60000 [=========================>....] - ETA: 2s - loss: 0.2151 - acc: 0.9342\u001b[0m\n",
      "\u001b[34m53888/60000 [=========================>....] - ETA: 2s - loss: 0.2147 - acc: 0.9343\u001b[0m\n",
      "\u001b[34m54080/60000 [==========================>...] - ETA: 2s - loss: 0.2143 - acc: 0.9344\u001b[0m\n",
      "\u001b[34m54272/60000 [==========================>...] - ETA: 2s - loss: 0.2141 - acc: 0.9345\u001b[0m\n",
      "\u001b[34m54464/60000 [==========================>...] - ETA: 2s - loss: 0.2138 - acc: 0.9346\u001b[0m\n",
      "\u001b[34m54656/60000 [==========================>...] - ETA: 2s - loss: 0.2133 - acc: 0.9347\u001b[0m\n",
      "\u001b[34m54848/60000 [==========================>...] - ETA: 1s - loss: 0.2130 - acc: 0.9348\u001b[0m\n",
      "\u001b[34m55040/60000 [==========================>...] - ETA: 1s - loss: 0.2129 - acc: 0.9348\u001b[0m\n",
      "\u001b[34m55232/60000 [==========================>...] - ETA: 1s - loss: 0.2125 - acc: 0.9349\u001b[0m\n",
      "\u001b[34m55424/60000 [==========================>...] - ETA: 1s - loss: 0.2119 - acc: 0.9351\u001b[0m\n",
      "\u001b[34m55616/60000 [==========================>...] - ETA: 1s - loss: 0.2117 - acc: 0.9351\u001b[0m\n",
      "\u001b[34m55808/60000 [==========================>...] - ETA: 1s - loss: 0.2112 - acc: 0.9353\u001b[0m\n",
      "\u001b[34m56000/60000 [===========================>..] - ETA: 1s - loss: 0.2109 - acc: 0.9353\u001b[0m\n",
      "\u001b[34m56192/60000 [===========================>..] - ETA: 1s - loss: 0.2104 - acc: 0.9355\u001b[0m\n",
      "\u001b[34m56384/60000 [===========================>..] - ETA: 1s - loss: 0.2098 - acc: 0.9356\u001b[0m\n",
      "\u001b[34m56576/60000 [===========================>..] - ETA: 1s - loss: 0.2094 - acc: 0.9357\u001b[0m\n",
      "\u001b[34m56768/60000 [===========================>..] - ETA: 1s - loss: 0.2092 - acc: 0.9358\u001b[0m\n",
      "\u001b[34m56960/60000 [===========================>..] - ETA: 1s - loss: 0.2087 - acc: 0.9359\u001b[0m\n",
      "\u001b[34m57152/60000 [===========================>..] - ETA: 1s - loss: 0.2082 - acc: 0.9360\u001b[0m\n",
      "\u001b[34m57344/60000 [===========================>..] - ETA: 0s - loss: 0.2080 - acc: 0.9362\u001b[0m\n",
      "\u001b[34m57536/60000 [===========================>..] - ETA: 0s - loss: 0.2078 - acc: 0.9362\u001b[0m\n",
      "\u001b[34m57728/60000 [===========================>..] - ETA: 0s - loss: 0.2075 - acc: 0.9363\u001b[0m\n",
      "\u001b[34m57920/60000 [===========================>..] - ETA: 0s - loss: 0.2071 - acc: 0.9364\u001b[0m\n",
      "\u001b[34m58112/60000 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9365\u001b[0m\n",
      "\u001b[34m58304/60000 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9366\u001b[0m\n",
      "\u001b[34m58496/60000 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9367\u001b[0m\n",
      "\u001b[34m58688/60000 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9368\u001b[0m\n",
      "\u001b[34m58880/60000 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9370\u001b[0m\n",
      "\u001b[34m59072/60000 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9371\u001b[0m\n",
      "\u001b[34m59264/60000 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9371\u001b[0m\n",
      "\u001b[34m59456/60000 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9372\u001b[0m\n",
      "\u001b[34m59584/60000 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9373\u001b[0m\n",
      "\u001b[34m59776/60000 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9374\u001b[0m\n",
      "\u001b[34m59968/60000 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9375\u001b[0m\n",
      "\u001b[34m60000/60000 [==============================] - 23s 387us/step - loss: 0.2038 - acc: 0.9375 - val_loss: 0.1594 - val_acc: 0.9486\u001b[0m\n",
      "\u001b[34mEpoch 2/2\n",
      "\n",
      "   64/60000 [..............................] - ETA: 22s - loss: 0.0823 - acc: 0.9531\n",
      "  192/60000 [..............................] - ETA: 23s - loss: 0.0424 - acc: 0.9844\n",
      "  384/60000 [..............................] - ETA: 22s - loss: 0.0561 - acc: 0.9818\n",
      "  576/60000 [..............................] - ETA: 21s - loss: 0.0613 - acc: 0.9844\n",
      "  768/60000 [..............................] - ETA: 20s - loss: 0.0705 - acc: 0.9766\n",
      "  960/60000 [..............................] - ETA: 21s - loss: 0.0668 - acc: 0.9771\n",
      " 1088/60000 [..............................] - ETA: 21s - loss: 0.0650 - acc: 0.9761\n",
      " 1280/60000 [..............................] - ETA: 21s - loss: 0.0625 - acc: 0.9773\n",
      " 1472/60000 [..............................] - ETA: 21s - loss: 0.0605 - acc: 0.9783\u001b[0m\n",
      "\u001b[34m 1600/60000 [..............................] - ETA: 21s - loss: 0.0624 - acc: 0.9775\n",
      " 1792/60000 [..............................] - ETA: 20s - loss: 0.0606 - acc: 0.9788\n",
      " 1984/60000 [..............................] - ETA: 20s - loss: 0.0578 - acc: 0.9798\n",
      " 2176/60000 [>.............................] - ETA: 20s - loss: 0.0629 - acc: 0.9793\n",
      " 2368/60000 [>.............................] - ETA: 20s - loss: 0.0626 - acc: 0.9797\n",
      " 2560/60000 [>.............................] - ETA: 20s - loss: 0.0675 - acc: 0.9789\n",
      " 2752/60000 [>.............................] - ETA: 20s - loss: 0.0671 - acc: 0.9789\n",
      " 2944/60000 [>.............................] - ETA: 20s - loss: 0.0651 - acc: 0.9800\n",
      " 3136/60000 [>.............................] - ETA: 20s - loss: 0.0679 - acc: 0.9786\n",
      " 3328/60000 [>.............................] - ETA: 20s - loss: 0.0717 - acc: 0.9781\n",
      " 3520/60000 [>.............................] - ETA: 20s - loss: 0.0724 - acc: 0.9784\n",
      " 3712/60000 [>.............................] - ETA: 20s - loss: 0.0718 - acc: 0.9779\n",
      " 3904/60000 [>.............................] - ETA: 19s - loss: 0.0702 - acc: 0.9785\n",
      " 4096/60000 [=>............................] - ETA: 19s - loss: 0.0729 - acc: 0.9783\n",
      " 4288/60000 [=>............................] - ETA: 19s - loss: 0.0708 - acc: 0.9790\u001b[0m\n",
      "\u001b[34m 4480/60000 [=>............................] - ETA: 19s - loss: 0.0709 - acc: 0.9790\n",
      " 4672/60000 [=>............................] - ETA: 19s - loss: 0.0725 - acc: 0.9790\n",
      " 4864/60000 [=>............................] - ETA: 19s - loss: 0.0747 - acc: 0.9786\n",
      " 5056/60000 [=>............................] - ETA: 19s - loss: 0.0734 - acc: 0.9790\n",
      " 5248/60000 [=>............................] - ETA: 19s - loss: 0.0766 - acc: 0.9779\n",
      " 5440/60000 [=>............................] - ETA: 19s - loss: 0.0753 - acc: 0.9783\n",
      " 5632/60000 [=>............................] - ETA: 19s - loss: 0.0767 - acc: 0.9778\n",
      " 5824/60000 [=>............................] - ETA: 19s - loss: 0.0776 - acc: 0.9775\n",
      " 6016/60000 [==>...........................] - ETA: 19s - loss: 0.0778 - acc: 0.9772\n",
      " 6208/60000 [==>...........................] - ETA: 18s - loss: 0.0769 - acc: 0.9773\n",
      " 6400/60000 [==>...........................] - ETA: 18s - loss: 0.0763 - acc: 0.9773\n",
      " 6592/60000 [==>...........................] - ETA: 18s - loss: 0.0758 - acc: 0.9774\n",
      " 6784/60000 [==>...........................] - ETA: 18s - loss: 0.0771 - acc: 0.9767\n",
      " 6976/60000 [==>...........................] - ETA: 18s - loss: 0.0776 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m 7168/60000 [==>...........................] - ETA: 18s - loss: 0.0766 - acc: 0.9766\n",
      " 7360/60000 [==>...........................] - ETA: 18s - loss: 0.0766 - acc: 0.9768\n",
      " 7552/60000 [==>...........................] - ETA: 18s - loss: 0.0761 - acc: 0.9771\n",
      " 7744/60000 [==>...........................] - ETA: 18s - loss: 0.0762 - acc: 0.9769\n",
      " 7936/60000 [==>...........................] - ETA: 18s - loss: 0.0762 - acc: 0.9769\n",
      " 8128/60000 [===>..........................] - ETA: 18s - loss: 0.0767 - acc: 0.9767\n",
      " 8320/60000 [===>..........................] - ETA: 18s - loss: 0.0776 - acc: 0.9762\n",
      " 8512/60000 [===>..........................] - ETA: 18s - loss: 0.0787 - acc: 0.9758\n",
      " 8704/60000 [===>..........................] - ETA: 18s - loss: 0.0788 - acc: 0.9758\n",
      " 8896/60000 [===>..........................] - ETA: 18s - loss: 0.0790 - acc: 0.9756\n",
      " 9088/60000 [===>..........................] - ETA: 17s - loss: 0.0804 - acc: 0.9750\n",
      " 9280/60000 [===>..........................] - ETA: 17s - loss: 0.0803 - acc: 0.9749\n",
      " 9472/60000 [===>..........................] - ETA: 17s - loss: 0.0794 - acc: 0.9753\n",
      " 9664/60000 [===>..........................] - ETA: 17s - loss: 0.0793 - acc: 0.9752\n",
      " 9856/60000 [===>..........................] - ETA: 17s - loss: 0.0783 - acc: 0.9754\u001b[0m\n",
      "\u001b[34m10048/60000 [====>.........................] - ETA: 17s - loss: 0.0808 - acc: 0.9747\u001b[0m\n",
      "\u001b[34m10240/60000 [====>.........................] - ETA: 17s - loss: 0.0821 - acc: 0.9748\u001b[0m\n",
      "\u001b[34m10432/60000 [====>.........................] - ETA: 17s - loss: 0.0813 - acc: 0.9751\u001b[0m\n",
      "\u001b[34m10624/60000 [====>.........................] - ETA: 17s - loss: 0.0816 - acc: 0.9749\u001b[0m\n",
      "\u001b[34m10816/60000 [====>.........................] - ETA: 17s - loss: 0.0807 - acc: 0.9752\u001b[0m\n",
      "\u001b[34m11008/60000 [====>.........................] - ETA: 17s - loss: 0.0803 - acc: 0.9755\u001b[0m\n",
      "\u001b[34m11200/60000 [====>.........................] - ETA: 17s - loss: 0.0805 - acc: 0.9751\u001b[0m\n",
      "\u001b[34m11392/60000 [====>.........................] - ETA: 17s - loss: 0.0802 - acc: 0.9751\u001b[0m\n",
      "\u001b[34m11584/60000 [====>.........................] - ETA: 17s - loss: 0.0798 - acc: 0.9752\u001b[0m\n",
      "\u001b[34m11776/60000 [====>.........................] - ETA: 16s - loss: 0.0799 - acc: 0.9754\u001b[0m\n",
      "\u001b[34m11968/60000 [====>.........................] - ETA: 16s - loss: 0.0793 - acc: 0.9755\u001b[0m\n",
      "\u001b[34m12160/60000 [=====>........................] - ETA: 16s - loss: 0.0786 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m12352/60000 [=====>........................] - ETA: 16s - loss: 0.0781 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m12544/60000 [=====>........................] - ETA: 16s - loss: 0.0787 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m12736/60000 [=====>........................] - ETA: 16s - loss: 0.0783 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m12928/60000 [=====>........................] - ETA: 16s - loss: 0.0777 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m13120/60000 [=====>........................] - ETA: 16s - loss: 0.0774 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m13248/60000 [=====>........................] - ETA: 16s - loss: 0.0779 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m13376/60000 [=====>........................] - ETA: 16s - loss: 0.0782 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m13568/60000 [=====>........................] - ETA: 16s - loss: 0.0779 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m13760/60000 [=====>........................] - ETA: 16s - loss: 0.0780 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m13952/60000 [=====>........................] - ETA: 16s - loss: 0.0783 - acc: 0.9754\u001b[0m\n",
      "\u001b[34m14144/60000 [======>.......................] - ETA: 16s - loss: 0.0781 - acc: 0.9755\u001b[0m\n",
      "\u001b[34m14336/60000 [======>.......................] - ETA: 16s - loss: 0.0784 - acc: 0.9754\u001b[0m\n",
      "\u001b[34m14528/60000 [======>.......................] - ETA: 16s - loss: 0.0784 - acc: 0.9753\u001b[0m\n",
      "\u001b[34m14720/60000 [======>.......................] - ETA: 15s - loss: 0.0784 - acc: 0.9752\u001b[0m\n",
      "\u001b[34m14912/60000 [======>.......................] - ETA: 15s - loss: 0.0788 - acc: 0.9750\u001b[0m\n",
      "\u001b[34m15104/60000 [======>.......................] - ETA: 15s - loss: 0.0787 - acc: 0.9750\u001b[0m\n",
      "\u001b[34m15296/60000 [======>.......................] - ETA: 15s - loss: 0.0784 - acc: 0.9752\u001b[0m\n",
      "\u001b[34m15488/60000 [======>.......................] - ETA: 15s - loss: 0.0777 - acc: 0.9754\u001b[0m\n",
      "\u001b[34m15680/60000 [======>.......................] - ETA: 15s - loss: 0.0774 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m15872/60000 [======>.......................] - ETA: 15s - loss: 0.0768 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m16064/60000 [=======>......................] - ETA: 15s - loss: 0.0770 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m16256/60000 [=======>......................] - ETA: 15s - loss: 0.0766 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m16448/60000 [=======>......................] - ETA: 15s - loss: 0.0772 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m16640/60000 [=======>......................] - ETA: 15s - loss: 0.0777 - acc: 0.9755\u001b[0m\n",
      "\u001b[34m16832/60000 [=======>......................] - ETA: 15s - loss: 0.0785 - acc: 0.9754\u001b[0m\n",
      "\u001b[34m17024/60000 [=======>......................] - ETA: 15s - loss: 0.0780 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m17216/60000 [=======>......................] - ETA: 15s - loss: 0.0778 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m17408/60000 [=======>......................] - ETA: 15s - loss: 0.0775 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m17600/60000 [=======>......................] - ETA: 14s - loss: 0.0774 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m17792/60000 [=======>......................] - ETA: 14s - loss: 0.0777 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m17984/60000 [=======>......................] - ETA: 14s - loss: 0.0771 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m18112/60000 [========>.....................] - ETA: 14s - loss: 0.0769 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m18304/60000 [========>.....................] - ETA: 14s - loss: 0.0766 - acc: 0.9760\u001b[0m\n",
      "\u001b[34m18496/60000 [========>.....................] - ETA: 14s - loss: 0.0766 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m18688/60000 [========>.....................] - ETA: 14s - loss: 0.0766 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m18880/60000 [========>.....................] - ETA: 14s - loss: 0.0765 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m19072/60000 [========>.....................] - ETA: 14s - loss: 0.0771 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m19264/60000 [========>.....................] - ETA: 14s - loss: 0.0768 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m19456/60000 [========>.....................] - ETA: 14s - loss: 0.0768 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m19648/60000 [========>.....................] - ETA: 14s - loss: 0.0766 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m19840/60000 [========>.....................] - ETA: 14s - loss: 0.0765 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m20032/60000 [=========>....................] - ETA: 14s - loss: 0.0763 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m20224/60000 [=========>....................] - ETA: 14s - loss: 0.0763 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m20416/60000 [=========>....................] - ETA: 13s - loss: 0.0770 - acc: 0.9760\u001b[0m\n",
      "\u001b[34m20608/60000 [=========>....................] - ETA: 13s - loss: 0.0774 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m20800/60000 [=========>....................] - ETA: 13s - loss: 0.0768 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m20992/60000 [=========>....................] - ETA: 13s - loss: 0.0768 - acc: 0.9760\u001b[0m\n",
      "\u001b[34m21184/60000 [=========>....................] - ETA: 13s - loss: 0.0764 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m21376/60000 [=========>....................] - ETA: 13s - loss: 0.0764 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m21568/60000 [=========>....................] - ETA: 13s - loss: 0.0768 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m21760/60000 [=========>....................] - ETA: 13s - loss: 0.0765 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m21952/60000 [=========>....................] - ETA: 13s - loss: 0.0768 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m22144/60000 [==========>...................] - ETA: 13s - loss: 0.0763 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m22336/60000 [==========>...................] - ETA: 13s - loss: 0.0764 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m22528/60000 [==========>...................] - ETA: 13s - loss: 0.0765 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m22720/60000 [==========>...................] - ETA: 13s - loss: 0.0771 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m22912/60000 [==========>...................] - ETA: 13s - loss: 0.0778 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m23104/60000 [==========>...................] - ETA: 12s - loss: 0.0775 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m23296/60000 [==========>...................] - ETA: 12s - loss: 0.0777 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m23488/60000 [==========>...................] - ETA: 12s - loss: 0.0773 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m23680/60000 [==========>...................] - ETA: 12s - loss: 0.0771 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m23872/60000 [==========>...................] - ETA: 12s - loss: 0.0767 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m24064/60000 [===========>..................] - ETA: 12s - loss: 0.0771 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m24256/60000 [===========>..................] - ETA: 12s - loss: 0.0774 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m24448/60000 [===========>..................] - ETA: 12s - loss: 0.0776 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m24640/60000 [===========>..................] - ETA: 12s - loss: 0.0775 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m24832/60000 [===========>..................] - ETA: 12s - loss: 0.0778 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m25024/60000 [===========>..................] - ETA: 12s - loss: 0.0780 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m25216/60000 [===========>..................] - ETA: 12s - loss: 0.0780 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m25408/60000 [===========>..................] - ETA: 12s - loss: 0.0779 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m25600/60000 [===========>..................] - ETA: 12s - loss: 0.0781 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m25792/60000 [===========>..................] - ETA: 12s - loss: 0.0779 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m25984/60000 [===========>..................] - ETA: 11s - loss: 0.0776 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m26176/60000 [============>.................] - ETA: 11s - loss: 0.0772 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m26368/60000 [============>.................] - ETA: 11s - loss: 0.0775 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m26560/60000 [============>.................] - ETA: 11s - loss: 0.0774 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m26752/60000 [============>.................] - ETA: 11s - loss: 0.0774 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m26944/60000 [============>.................] - ETA: 11s - loss: 0.0781 - acc: 0.9755\u001b[0m\n",
      "\u001b[34m27136/60000 [============>.................] - ETA: 11s - loss: 0.0780 - acc: 0.9755\u001b[0m\n",
      "\u001b[34m27328/60000 [============>.................] - ETA: 11s - loss: 0.0777 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m27520/60000 [============>.................] - ETA: 11s - loss: 0.0775 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m27648/60000 [============>.................] - ETA: 11s - loss: 0.0772 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m27776/60000 [============>.................] - ETA: 11s - loss: 0.0771 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m27968/60000 [============>.................] - ETA: 11s - loss: 0.0769 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m28160/60000 [=============>................] - ETA: 11s - loss: 0.0775 - acc: 0.9757\u001b[0m\n",
      "\u001b[34m28352/60000 [=============>................] - ETA: 11s - loss: 0.0773 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m28544/60000 [=============>................] - ETA: 11s - loss: 0.0774 - acc: 0.9758\u001b[0m\n",
      "\u001b[34m28736/60000 [=============>................] - ETA: 11s - loss: 0.0770 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m28928/60000 [=============>................] - ETA: 10s - loss: 0.0772 - acc: 0.9759\u001b[0m\n",
      "\u001b[34m29120/60000 [=============>................] - ETA: 10s - loss: 0.0770 - acc: 0.9760\u001b[0m\n",
      "\u001b[34m29312/60000 [=============>................] - ETA: 10s - loss: 0.0771 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m29440/60000 [=============>................] - ETA: 10s - loss: 0.0772 - acc: 0.9760\u001b[0m\n",
      "\u001b[34m29568/60000 [=============>................] - ETA: 10s - loss: 0.0770 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m29760/60000 [=============>................] - ETA: 10s - loss: 0.0767 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m29952/60000 [=============>................] - ETA: 10s - loss: 0.0767 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m30144/60000 [==============>...............] - ETA: 10s - loss: 0.0768 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m30336/60000 [==============>...............] - ETA: 10s - loss: 0.0769 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m30528/60000 [==============>...............] - ETA: 10s - loss: 0.0771 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m30720/60000 [==============>...............] - ETA: 10s - loss: 0.0772 - acc: 0.9761\u001b[0m\n",
      "\u001b[34m30912/60000 [==============>...............] - ETA: 10s - loss: 0.0770 - acc: 0.9762\u001b[0m\n",
      "\u001b[34m31104/60000 [==============>...............] - ETA: 10s - loss: 0.0767 - acc: 0.9763\u001b[0m\n",
      "\u001b[34m31296/60000 [==============>...............] - ETA: 10s - loss: 0.0766 - acc: 0.9763\u001b[0m\n",
      "\u001b[34m31488/60000 [==============>...............] - ETA: 10s - loss: 0.0764 - acc: 0.9764\u001b[0m\n",
      "\u001b[34m31680/60000 [==============>...............] - ETA: 10s - loss: 0.0763 - acc: 0.9764\u001b[0m\n",
      "\u001b[34m31872/60000 [==============>...............] - ETA: 9s - loss: 0.0762 - acc: 0.9765 \u001b[0m\n",
      "\u001b[34m32064/60000 [===============>..............] - ETA: 9s - loss: 0.0762 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m32256/60000 [===============>..............] - ETA: 9s - loss: 0.0761 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m32448/60000 [===============>..............] - ETA: 9s - loss: 0.0759 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m32640/60000 [===============>..............] - ETA: 9s - loss: 0.0757 - acc: 0.9766\u001b[0m\n",
      "\n",
      "2019-12-01 07:55:53 Uploading - Uploading generated training model\u001b[34m32832/60000 [===============>..............] - ETA: 9s - loss: 0.0757 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m33024/60000 [===============>..............] - ETA: 9s - loss: 0.0755 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m33216/60000 [===============>..............] - ETA: 9s - loss: 0.0756 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m33408/60000 [===============>..............] - ETA: 9s - loss: 0.0755 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m33600/60000 [===============>..............] - ETA: 9s - loss: 0.0756 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m33792/60000 [===============>..............] - ETA: 9s - loss: 0.0755 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m33984/60000 [===============>..............] - ETA: 9s - loss: 0.0757 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m34176/60000 [================>.............] - ETA: 9s - loss: 0.0757 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m34368/60000 [================>.............] - ETA: 9s - loss: 0.0755 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m34560/60000 [================>.............] - ETA: 8s - loss: 0.0759 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m34752/60000 [================>.............] - ETA: 8s - loss: 0.0758 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m34944/60000 [================>.............] - ETA: 8s - loss: 0.0755 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m35136/60000 [================>.............] - ETA: 8s - loss: 0.0753 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m35328/60000 [================>.............] - ETA: 8s - loss: 0.0756 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m35520/60000 [================>.............] - ETA: 8s - loss: 0.0755 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m35712/60000 [================>.............] - ETA: 8s - loss: 0.0755 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m35904/60000 [================>.............] - ETA: 8s - loss: 0.0755 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m36096/60000 [=================>............] - ETA: 8s - loss: 0.0756 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m36288/60000 [=================>............] - ETA: 8s - loss: 0.0754 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m36480/60000 [=================>............] - ETA: 8s - loss: 0.0756 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m36672/60000 [=================>............] - ETA: 8s - loss: 0.0756 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m36864/60000 [=================>............] - ETA: 8s - loss: 0.0755 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m37056/60000 [=================>............] - ETA: 8s - loss: 0.0754 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m37248/60000 [=================>............] - ETA: 8s - loss: 0.0754 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m37440/60000 [=================>............] - ETA: 7s - loss: 0.0755 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m37632/60000 [=================>............] - ETA: 7s - loss: 0.0757 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m37824/60000 [=================>............] - ETA: 7s - loss: 0.0758 - acc: 0.9765\u001b[0m\n",
      "\u001b[34m38016/60000 [==================>...........] - ETA: 7s - loss: 0.0756 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m38208/60000 [==================>...........] - ETA: 7s - loss: 0.0757 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m38336/60000 [==================>...........] - ETA: 7s - loss: 0.0759 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m38528/60000 [==================>...........] - ETA: 7s - loss: 0.0762 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m38720/60000 [==================>...........] - ETA: 7s - loss: 0.0760 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m38912/60000 [==================>...........] - ETA: 7s - loss: 0.0758 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m39104/60000 [==================>...........] - ETA: 7s - loss: 0.0756 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m39296/60000 [==================>...........] - ETA: 7s - loss: 0.0754 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m39488/60000 [==================>...........] - ETA: 7s - loss: 0.0755 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m39680/60000 [==================>...........] - ETA: 7s - loss: 0.0756 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m39872/60000 [==================>...........] - ETA: 7s - loss: 0.0757 - acc: 0.9766\u001b[0m\n",
      "\u001b[34m40000/60000 [===================>..........] - ETA: 7s - loss: 0.0757 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m40128/60000 [===================>..........] - ETA: 6s - loss: 0.0757 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m40320/60000 [===================>..........] - ETA: 6s - loss: 0.0756 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m40512/60000 [===================>..........] - ETA: 6s - loss: 0.0756 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m40704/60000 [===================>..........] - ETA: 6s - loss: 0.0754 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m40896/60000 [===================>..........] - ETA: 6s - loss: 0.0755 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m41088/60000 [===================>..........] - ETA: 6s - loss: 0.0755 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m41280/60000 [===================>..........] - ETA: 6s - loss: 0.0754 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m41472/60000 [===================>..........] - ETA: 6s - loss: 0.0753 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m41664/60000 [===================>..........] - ETA: 6s - loss: 0.0752 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m41856/60000 [===================>..........] - ETA: 6s - loss: 0.0753 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m42048/60000 [====================>.........] - ETA: 6s - loss: 0.0754 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m42240/60000 [====================>.........] - ETA: 6s - loss: 0.0752 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m42432/60000 [====================>.........] - ETA: 6s - loss: 0.0754 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m42624/60000 [====================>.........] - ETA: 6s - loss: 0.0753 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m42816/60000 [====================>.........] - ETA: 6s - loss: 0.0754 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m43008/60000 [====================>.........] - ETA: 5s - loss: 0.0752 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m43200/60000 [====================>.........] - ETA: 5s - loss: 0.0751 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m43392/60000 [====================>.........] - ETA: 5s - loss: 0.0753 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m43584/60000 [====================>.........] - ETA: 5s - loss: 0.0754 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m43776/60000 [====================>.........] - ETA: 5s - loss: 0.0754 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m43904/60000 [====================>.........] - ETA: 5s - loss: 0.0753 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m44096/60000 [=====================>........] - ETA: 5s - loss: 0.0753 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m44288/60000 [=====================>........] - ETA: 5s - loss: 0.0755 - acc: 0.9767\u001b[0m\n",
      "\u001b[34m44480/60000 [=====================>........] - ETA: 5s - loss: 0.0752 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m44672/60000 [=====================>........] - ETA: 5s - loss: 0.0750 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m44864/60000 [=====================>........] - ETA: 5s - loss: 0.0753 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m45056/60000 [=====================>........] - ETA: 5s - loss: 0.0752 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m45248/60000 [=====================>........] - ETA: 5s - loss: 0.0752 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m45440/60000 [=====================>........] - ETA: 5s - loss: 0.0753 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m45632/60000 [=====================>........] - ETA: 5s - loss: 0.0751 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m45824/60000 [=====================>........] - ETA: 4s - loss: 0.0751 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m46016/60000 [======================>.......] - ETA: 4s - loss: 0.0751 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m46208/60000 [======================>.......] - ETA: 4s - loss: 0.0750 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m46400/60000 [======================>.......] - ETA: 4s - loss: 0.0748 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m46592/60000 [======================>.......] - ETA: 4s - loss: 0.0748 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m46784/60000 [======================>.......] - ETA: 4s - loss: 0.0748 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m46976/60000 [======================>.......] - ETA: 4s - loss: 0.0747 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m47168/60000 [======================>.......] - ETA: 4s - loss: 0.0749 - acc: 0.9768\u001b[0m\n",
      "\u001b[34m47360/60000 [======================>.......] - ETA: 4s - loss: 0.0749 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m47552/60000 [======================>.......] - ETA: 4s - loss: 0.0747 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m47744/60000 [======================>.......] - ETA: 4s - loss: 0.0747 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m47936/60000 [======================>.......] - ETA: 4s - loss: 0.0750 - acc: 0.9769\u001b[0m\n",
      "\u001b[34m48128/60000 [=======================>......] - ETA: 4s - loss: 0.0750 - acc: 0.9770\u001b[0m\n",
      "\u001b[34m48320/60000 [=======================>......] - ETA: 4s - loss: 0.0750 - acc: 0.9770\u001b[0m\n",
      "\u001b[34m48512/60000 [=======================>......] - ETA: 4s - loss: 0.0750 - acc: 0.9770\u001b[0m\n",
      "\u001b[34m48704/60000 [=======================>......] - ETA: 3s - loss: 0.0747 - acc: 0.9771\u001b[0m\n",
      "\u001b[34m48896/60000 [=======================>......] - ETA: 3s - loss: 0.0747 - acc: 0.9771\u001b[0m\n",
      "\u001b[34m49088/60000 [=======================>......] - ETA: 3s - loss: 0.0746 - acc: 0.9771\u001b[0m\n",
      "\u001b[34m49280/60000 [=======================>......] - ETA: 3s - loss: 0.0745 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m49472/60000 [=======================>......] - ETA: 3s - loss: 0.0744 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m49664/60000 [=======================>......] - ETA: 3s - loss: 0.0743 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m49856/60000 [=======================>......] - ETA: 3s - loss: 0.0743 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m50048/60000 [========================>.....] - ETA: 3s - loss: 0.0742 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m50240/60000 [========================>.....] - ETA: 3s - loss: 0.0743 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m50432/60000 [========================>.....] - ETA: 3s - loss: 0.0745 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m50624/60000 [========================>.....] - ETA: 3s - loss: 0.0746 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m50816/60000 [========================>.....] - ETA: 3s - loss: 0.0745 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m51008/60000 [========================>.....] - ETA: 3s - loss: 0.0748 - acc: 0.9771\u001b[0m\n",
      "\u001b[34m51200/60000 [========================>.....] - ETA: 3s - loss: 0.0747 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m51392/60000 [========================>.....] - ETA: 3s - loss: 0.0748 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m51584/60000 [========================>.....] - ETA: 2s - loss: 0.0746 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m51776/60000 [========================>.....] - ETA: 2s - loss: 0.0745 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m51968/60000 [========================>.....] - ETA: 2s - loss: 0.0746 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m52160/60000 [=========================>....] - ETA: 2s - loss: 0.0744 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m52352/60000 [=========================>....] - ETA: 2s - loss: 0.0745 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m52544/60000 [=========================>....] - ETA: 2s - loss: 0.0745 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m52672/60000 [=========================>....] - ETA: 2s - loss: 0.0745 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m52864/60000 [=========================>....] - ETA: 2s - loss: 0.0744 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m53056/60000 [=========================>....] - ETA: 2s - loss: 0.0742 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m53248/60000 [=========================>....] - ETA: 2s - loss: 0.0741 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m53440/60000 [=========================>....] - ETA: 2s - loss: 0.0740 - acc: 0.9774\u001b[0m\n",
      "\u001b[34m53632/60000 [=========================>....] - ETA: 2s - loss: 0.0741 - acc: 0.9774\u001b[0m\n",
      "\u001b[34m53824/60000 [=========================>....] - ETA: 2s - loss: 0.0741 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m54016/60000 [==========================>...] - ETA: 2s - loss: 0.0742 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m54208/60000 [==========================>...] - ETA: 2s - loss: 0.0745 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m54400/60000 [==========================>...] - ETA: 1s - loss: 0.0745 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m54592/60000 [==========================>...] - ETA: 1s - loss: 0.0744 - acc: 0.9772\u001b[0m\n",
      "\u001b[34m54784/60000 [==========================>...] - ETA: 1s - loss: 0.0742 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m54976/60000 [==========================>...] - ETA: 1s - loss: 0.0741 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m55168/60000 [==========================>...] - ETA: 1s - loss: 0.0740 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m55360/60000 [==========================>...] - ETA: 1s - loss: 0.0740 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m55552/60000 [==========================>...] - ETA: 1s - loss: 0.0739 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m55680/60000 [==========================>...] - ETA: 1s - loss: 0.0739 - acc: 0.9773\u001b[0m\n",
      "\u001b[34m55872/60000 [==========================>...] - ETA: 1s - loss: 0.0738 - acc: 0.9774\u001b[0m\n",
      "\u001b[34m56064/60000 [===========================>..] - ETA: 1s - loss: 0.0736 - acc: 0.9774\u001b[0m\n",
      "\u001b[34m56256/60000 [===========================>..] - ETA: 1s - loss: 0.0735 - acc: 0.9774\u001b[0m\n",
      "\u001b[34m56448/60000 [===========================>..] - ETA: 1s - loss: 0.0734 - acc: 0.9774\u001b[0m\n",
      "\u001b[34m56576/60000 [===========================>..] - ETA: 1s - loss: 0.0733 - acc: 0.9775\u001b[0m\n",
      "\u001b[34m56768/60000 [===========================>..] - ETA: 1s - loss: 0.0732 - acc: 0.9775\u001b[0m\n",
      "\u001b[34m56960/60000 [===========================>..] - ETA: 1s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m57152/60000 [===========================>..] - ETA: 1s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m57344/60000 [===========================>..] - ETA: 0s - loss: 0.0729 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m57536/60000 [===========================>..] - ETA: 0s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m57728/60000 [===========================>..] - ETA: 0s - loss: 0.0729 - acc: 0.9777\u001b[0m\n",
      "\u001b[34m57920/60000 [===========================>..] - ETA: 0s - loss: 0.0729 - acc: 0.9777\u001b[0m\n",
      "\u001b[34m58112/60000 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m58304/60000 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m58496/60000 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m58688/60000 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m58880/60000 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m59072/60000 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m59264/60000 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m59456/60000 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m59648/60000 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m59840/60000 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9776\u001b[0m\n",
      "\u001b[34m60000/60000 [==============================] - 22s 364us/step - loss: 0.0730 - acc: 0.9776 - val_loss: 0.0753 - val_acc: 0.9761\u001b[0m\n",
      "\u001b[34mTest loss: 0.07533680940545164\u001b[0m\n",
      "\u001b[34mTest accuracy: 0.9761\u001b[0m\n",
      "\u001b[34mW1201 07:55:51.482933 140660131501824 deprecation.py:323] From keras_tf_mnist.py:97: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\u001b[0m\n",
      "\u001b[34mW1201 07:55:51.483247 140660131501824 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\n",
      "2019-12-01 07:55:59 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n",
      "job name: keras-tf-mnist-c7522fa-2019-12-01-07-52-16\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "\n",
    "commit = \"c7522fa\"\n",
    "git_config = {'repo': 'git@github.com:kazuya-iwami/sagemaker-sample.git',\n",
    "              'branch': 'master',\n",
    "              'commit': commit}\n",
    "\n",
    "job_name = \"project1-keras-tf-mnist-{}-{}\".format(commit, strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "role = 'arn:aws:iam::219819523389:role/service-role/AmazonSageMaker-ExecutionRole-20191127T135552'\n",
    "\n",
    "estimator = TensorFlow(entry_point = \"keras_tf_mnist.py\",\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.m4.xlarge\",\n",
    "          framework_version=\"1.14.0\",\n",
    "          py_version='py3',\n",
    "          script_mode=True,\n",
    "          git_config=git_config,\n",
    "          source_dir='project1',\n",
    "          hyperparameters={'batch-size': 64,\n",
    "                         'n-class': 10,\n",
    "                         'epochs': 2})\n",
    "\n",
    "estimator.fit(inputs=input_data, job_name=job_name) \n",
    "latest_training_job_name = estimator.latest_training_job.name\n",
    "print(\"job name: {}\".format(latest_training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMakerを利用して推論用APIを起動\n",
    "\n",
    "推論を行うために学習したモデルをデプロイします。`deploy()` メソッドでは、デプロイ先エンドポイントのインスタンス数、インスタンスタイプを指定します。ここではSageMakerの推論用インスタンスを起動し、推論用APIを生成します。\n",
    "\n",
    "SageMakerでTensorFlowを利用する場合、推論用エンドポイントには[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)が利用されます。推論時に独自の前処理や後処理を実行したい場合は[こちら](https://sagemaker.readthedocs.io/en/stable/using_tf.html#create-python-scripts-for-custom-input-and-output-formats)を参考に推論用のPython Scriptを指定できます。\n",
    "\n",
    "![図3](./images/image3.jpg \"図3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted labels are: [7 0 7 9 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 実際にランダムな5個の画像を入力し推論APIの動作を確認\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(x_test.shape[0] - 1), num_samples)\n",
    "images, labels = x_test[indices]/255, y_test[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "prediction = predictor.predict(images.reshape(num_samples, 28, 28, 1))['predictions']\n",
    "prediction = np.array(prediction)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('The predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンドポイントの削除\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足： 非同期で学習ジョブを実行する例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data, wait=False) #wait=Falseで非同期実行\n",
    "latest_training_job_name = estimator.latest_training_job.name\n",
    "print(\"job name: {}\".format(latest_training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の進捗確認 \n",
    "# InProgressがCompletedに変われば学習終了\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(\n",
    "    TrainingJobName=latest_training_job_name\n",
    ")\n",
    "print(desc[\"TrainingJobStatus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved in S3: s3://sagemaker-ap-northeast-1-219819523389/tensorflow-training-2019-11-30-15-26-22-334/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 学習済みモデルのS3パスも確認可能\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(\n",
    "    TrainingJobName=latest_training_job_name\n",
    ")\n",
    "# import pprint\n",
    "# pprint.pprint(desc)\n",
    "model_path = desc[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(\"model is saved in S3: {}\".format(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = estimator.attach(training_job_name=latest_training_job_name) \n",
    "predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンドポイントの削除\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足：オンプレミスで学習済みモデルをSageMakerでデプロイする例\n",
    "1. オンプレミスで学習\n",
    "1. tf.saved_model.simple_saveでモデルを保存しtarで圧縮\n",
    "1. S3にアップロード(これをModel Artifactと呼ぶ)\n",
    "1. 以下を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model_path = \"s3://\" #Model ArtifactのS3pathを指定\n",
    "model = Model(\n",
    "    model_path,\n",
    "    role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version=\"1.14.0\",\n",
    ")\n",
    "predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンドポイントの削除\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 運用環境について考える\n",
    "\n",
    "ここまでは、SageMaker Python SDKを利用して、人がアドホックに学習/推論を行う方法を示しました。\n",
    "実際の現場では、本番環境に導入する際は定期的に増加したデータで再学習を行い、自動でAPIをアップデートする仕組みが必要となるケースがあります。\n",
    "\n",
    "Under cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
